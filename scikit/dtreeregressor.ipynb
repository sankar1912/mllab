{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.028828332223689e-05\n",
      "First 10 Predictions: [-0.01469067  0.00126027  0.00014073  0.00126027  0.02717982 -0.04211407\n",
      "  0.00126027  0.00126027  0.00126027  0.05198032]\n",
      "Feature Importances:\n",
      "ISE_USD: 0.9634\n",
      "SP: 0.0026\n",
      "DAX: 0.0000\n",
      "FTSE: 0.0054\n",
      "NIKKEI: 0.0105\n",
      "BOVESPA: 0.0066\n",
      "EU: 0.0022\n",
      "EM: 0.0092\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"istanbul_stock_exchange.csv\")  # Ensure the file is in the correct location\n",
    "\n",
    "# Define features (independent variables) and target (dependent variable)\n",
    "X = df.drop(columns=['ISE_TL','date'])  # All other indices as features\n",
    "y = df['ISE_TL']  # Target variable\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Decision Tree model\n",
    "tree_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Evaluate model using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Print some predictions\n",
    "print(\"First 10 Predictions:\", y_pred[:10])\n",
    "\n",
    "# Print feature importance\n",
    "importances = tree_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(feature_names, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"user_id\": [101, 102, 103, 104, 105, 106, 107, 108],\n",
    "    \"user_reputation\": [50, 20, 80, 15, 60, 30, 10, 90],\n",
    "    \"reply_count\": [5, 1, 8, 2, 6, 3, 0, 10],\n",
    "    \"thumbs_up\": [15, 3, 25, 4, 20, 5, 2, 30],\n",
    "    \"thumbs_down\": [2, 4, 0, 5, 1, 3, 6, 0],\n",
    "    \"stars\": [5, 2, 4, 3, 5, 3, 1, 5],  # Target column\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'stars' into binary classification (Positive: 1, Negative: 0)\n",
    "df[\"sentiment\"] = df[\"stars\"].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "# Select features and target\n",
    "X = df[[\"user_reputation\", \"reply_count\", \"thumbs_up\", \"thumbs_down\"]].values\n",
    "y = df[\"sentiment\"].values\n",
    "\n",
    "# Function to calculate Gini Impurity\n",
    "def gini_impurity(y):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    prob = counts / len(y)\n",
    "    return 1 - np.sum(prob ** 2)\n",
    "\n",
    "# Function to find the best split\n",
    "def best_split(X, y):\n",
    "    best_gini = 1\n",
    "    best_feature, best_value = None, None\n",
    "\n",
    "    for feature in range(X.shape[1]):\n",
    "        values = np.unique(X[:, feature])\n",
    "        for val in values:\n",
    "            left_mask = X[:, feature] <= val\n",
    "            right_mask = ~left_mask\n",
    "\n",
    "            if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "                continue\n",
    "\n",
    "            gini_left = gini_impurity(y[left_mask])\n",
    "            gini_right = gini_impurity(y[right_mask])\n",
    "            gini = (len(y[left_mask]) * gini_left + len(y[right_mask]) * gini_right) / len(y)\n",
    "\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_feature = feature\n",
    "                best_value = val\n",
    "\n",
    "    return best_feature, best_value\n",
    "\n",
    "# Class for tree nodes\n",
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, left=None, right=None, label=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.label = label\n",
    "\n",
    "# Function to build the decision tree\n",
    "def build_tree(X, y, depth=0, max_depth=3):\n",
    "    if len(set(y)) == 1:  # If all labels are the same, return a leaf node\n",
    "        return Node(label=y[0])\n",
    "\n",
    "    if depth >= max_depth:  # Stop splitting if max depth is reached\n",
    "        return Node(label=np.bincount(y).argmax())\n",
    "\n",
    "    feature, value = best_split(X, y)\n",
    "    if feature is None:\n",
    "        return Node(label=np.bincount(y).argmax())\n",
    "\n",
    "    left_mask = X[:, feature] <= value\n",
    "    right_mask = ~left_mask\n",
    "\n",
    "    left_subtree = build_tree(X[left_mask], y[left_mask], depth + 1, max_depth)\n",
    "    right_subtree = build_tree(X[right_mask], y[right_mask], depth + 1, max_depth)\n",
    "\n",
    "    return Node(feature, value, left_subtree, right_subtree)\n",
    "\n",
    "# Function to predict using the tree\n",
    "def predict_tree(node, x):\n",
    "    if node.label is not None:\n",
    "        return node.label\n",
    "    if x[node.feature] <= node.value:\n",
    "        return predict_tree(node.left, x)\n",
    "    return predict_tree(node.right, x)\n",
    "\n",
    "# Train the Decision Tree\n",
    "tree = build_tree(X, y, max_depth=3)\n",
    "\n",
    "# Predict on new data (Example)\n",
    "new_data = np.array([[40, 4, 10, 2], [15, 2, 3, 5], [75, 8, 30, 1]])  # Example test data\n",
    "predictions = [predict_tree(tree, x) for x in new_data]\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8583997800384933\n",
      "First 10 Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"reciepe_reviews.csv\") \n",
    "df[\"sentiment\"] = df[\"stars\"].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "features = [\"user_reputation\", \"reply_count\", \"thumbs_up\", \n",
    "            \"thumbs_down\", \"best_score\", \"recipe_number\"]\n",
    "X = df[features]\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"First 10 Predictions:\", y_pred[100:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6861464420763149\n",
      "Predictions: [1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = {\n",
    "    \"user_id\": [101, 102, 103, 104, 105, 106, 107, 108],\n",
    "    \"user_reputation\": [50, 20, 80, 15, 60, 30, 10, 90],\n",
    "    \"reply_count\": [5, 1, 8, 2, 6, 3, 0, 10],\n",
    "    \"thumbs_up\": [15, 3, 25, 4, 20, 5, 2, 30],\n",
    "    \"thumbs_down\": [2, 4, 0, 5, 1, 3, 6, 0],\n",
    "    \"stars\": [5, 2, 4, 3, 5, 3, 1, 5],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[\"sentiment\"] = df[\"stars\"].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "X = df[[\"user_reputation\", \"reply_count\", \"thumbs_up\", \"thumbs_down\"]].values\n",
    "y = df[\"sentiment\"].values\n",
    "\n",
    "def gini_impurity(y):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    prob = counts / len(y)\n",
    "    return 1 - np.sum(prob ** 2)\n",
    "\n",
    "def best_split(X, y):\n",
    "    best_gini = 1\n",
    "    best_feature, best_value = None, None\n",
    "\n",
    "    for feature in range(X.shape[1]):\n",
    "        values = np.unique(X[:, feature])\n",
    "        for val in values:\n",
    "            left_mask = X[:, feature] <= val\n",
    "            right_mask = ~left_mask\n",
    "\n",
    "            if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "                continue\n",
    "\n",
    "            gini_left = gini_impurity(y[left_mask])\n",
    "            gini_right = gini_impurity(y[right_mask])\n",
    "            gini = (len(y[left_mask]) * gini_left + len(y[right_mask]) * gini_right) / len(y)\n",
    "\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_feature = feature\n",
    "                best_value = val\n",
    "\n",
    "    return best_feature, best_value\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, left=None, right=None, label=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.label = label\n",
    "\n",
    "def build_tree(X, y, depth=0, max_depth=3):\n",
    "    if len(set(y)) == 1: \n",
    "        return Node(label=y[0])\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        return Node(label=np.bincount(y).argmax())\n",
    "\n",
    "    feature, value = best_split(X, y)\n",
    "    if feature is None:\n",
    "        return Node(label=np.bincount(y).argmax())\n",
    "\n",
    "    left_mask = X[:, feature] <= value\n",
    "    right_mask = ~left_mask\n",
    "\n",
    "    left_subtree = build_tree(X[left_mask], y[left_mask], depth + 1, max_depth)\n",
    "    right_subtree = build_tree(X[right_mask], y[right_mask], depth + 1, max_depth)\n",
    "\n",
    "    return Node(feature, value, left_subtree, right_subtree)\n",
    "\n",
    "def predict_tree(node, x):\n",
    "    if node.label is not None:\n",
    "        return node.label\n",
    "    if x[node.feature] <= node.value:\n",
    "        return predict_tree(node.left, x)\n",
    "    return predict_tree(node.right, x)\n",
    "\n",
    "\n",
    "tree = build_tree(X, y, max_depth=3)\n",
    "\n",
    "new_data = np.array([[40, 4, 10, 2], [15, 2, 3, 5], [75, 8, 30, 1]])  # Example test data\n",
    "predictions = [predict_tree(tree, x) for x in new_data]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy_score(y_train, y_pred[:len(y_train)]))\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772614792411328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.13      0.20       340\n",
      "           1       1.00      0.02      0.04        46\n",
      "           2       0.00      0.00      0.00        44\n",
      "           3       0.00      0.00      0.00        98\n",
      "           4       0.35      0.18      0.24       321\n",
      "           5       0.80      0.97      0.88      2788\n",
      "\n",
      "    accuracy                           0.77      3637\n",
      "   macro avg       0.43      0.22      0.23      3637\n",
      "weighted avg       0.70      0.77      0.71      3637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "data = pd.read_csv('reciepe_reviews.csv')\n",
    "\n",
    "X = data['text']\n",
    "y = data['stars']\n",
    "X=X.fillna('')\n",
    "y=y.fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8022219777802222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "data = pd.read_csv('reciepe_reviews.csv')\n",
    "\n",
    "X = data['text']\n",
    "y = data['stars']\n",
    "X=X.fillna('')\n",
    "y=y.fillna(0)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    return text\n",
    "X = X.apply(preprocess_text)\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_word_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        total_count = len(y)\n",
    "        for label in y:\n",
    "            self.class_priors[label] = self.class_priors.get(label, 0) + 1\n",
    "        for i in range(len(X)):\n",
    "            label = y[i]\n",
    "            words = X[i].split()\n",
    "            self.class_word_counts[label] += len(words)\n",
    "            for word in words:\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "        for label in self.class_priors:\n",
    "            self.class_priors[label] /= total_count\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text in X:\n",
    "            words = text.split()\n",
    "            class_scores = {}\n",
    "            for label in self.class_priors:\n",
    "                score = np.log(self.class_priors[label])\n",
    "                for word in words:\n",
    "                    word_count = self.word_counts[label][word]\n",
    "                    total_count = self.class_word_counts[label]\n",
    "                    score += np.log((word_count + 1) / (total_count + len(self.vocab)))\n",
    "                class_scores[label] = score\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        return predictions\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X, y)\n",
    "\n",
    "y_pred = nb.predict(X)\n",
    "\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
